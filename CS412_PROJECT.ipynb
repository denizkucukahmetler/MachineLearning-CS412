{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS412 PROJECT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAGmpIY4ro6A"
      },
      "source": [
        "# CS 412 Machine Learning Kaggle Prediction and Processing Codes\n",
        "\n",
        "###Berk Turhan\n",
        "###Deniz Küçükahmetler\n",
        "###Zeynep Kılınç"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPJNQA4C1Ago",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09f4fddd-8d4e-4cf8-966a-db519f683d00"
      },
      "source": [
        "#mount to drive\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"./drive\")\n",
        "\n",
        "path_prefix = \"./drive/My Drive\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from os.path import join\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at ./drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjuj77KLipT1"
      },
      "source": [
        "fname = \"train.xlsx\"\n",
        "\n",
        "df_ = pd.read_excel(join(path_prefix, fname))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6OIIgeuiMkT"
      },
      "source": [
        "**Task 2 - Prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgCWN_ylu8CY"
      },
      "source": [
        "### PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr1RLG6WKwbp"
      },
      "source": [
        "#Check na values in coulmns\n",
        "#check the nan value count in the columns\n",
        "df_.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_kTdMZMKpsd"
      },
      "source": [
        "\n",
        "df_['LearningPlatformUsefulnessBlogs'] = df_['LearningPlatformUsefulnessBlogs'].fillna(\"no comment\")\n",
        "df_['LearningPlatformUsefulnessKaggle'] = df_['LearningPlatformUsefulnessKaggle'].fillna(\"no comment\")\n",
        "df_['LearningPlatformUsefulnessCourses'] = df_['LearningPlatformUsefulnessCourses'].fillna(\"no comment\")\n",
        "df_['LearningPlatformUsefulnessProjects'] = df_['LearningPlatformUsefulnessProjects'].fillna(\"no comment\")\n",
        "df_['LearningPlatformUsefulnessSO'] = df_['LearningPlatformUsefulnessSO'].fillna(\"no comment\")\n",
        "df_['LearningPlatformUsefulnessTextbook'] = df_['LearningPlatformUsefulnessTextbook'].fillna(\"no comment\")\n",
        "df_['LearningPlatformUsefulnessYouTube'] = df_['LearningPlatformUsefulnessYouTube'].fillna(\"no comment\")\n",
        "\n",
        "df_['WorkToolsFrequencyPython'] = df_['WorkToolsFrequencyPython'].fillna(\"no comment\")\n",
        "df_['WorkToolsFrequencyR'] = df_['WorkToolsFrequencyR'].fillna(\"no comment\")\n",
        "df_['WorkToolsFrequencySQL'] = df_['WorkToolsFrequencySQL'].fillna(\"no comment\")\n",
        "df_['WorkMethodsFrequencyCross-Validation'] = df_['WorkMethodsFrequencyCross-Validation'].fillna(\"no comment\")\n",
        "df_['WorkMethodsFrequencyDataVisualization'] = df_['WorkMethodsFrequencyDataVisualization'].fillna(\"no comment\")\n",
        "df_['WorkMethodsFrequencyDecisionTrees'] = df_['WorkMethodsFrequencyDecisionTrees'].fillna(\"no comment\")\n",
        "df_['WorkMethodsFrequencyLogisticRegression'] = df_['WorkMethodsFrequencyLogisticRegression'].fillna(\"no comment\")\n",
        "df_['WorkMethodsFrequencyNeuralNetworks'] = df_['WorkMethodsFrequencyNeuralNetworks'].fillna(\"no comment\")\n",
        "df_['WorkMethodsFrequencyPCA'] = df_['WorkMethodsFrequencyPCA'].fillna(\"no comment\")\n",
        "df_['WorkMethodsFrequencyRandomForests'] = df_['WorkMethodsFrequencyRandomForests'].fillna(\"no comment\")\n",
        "df_['WorkMethodsFrequencyTimeSeriesAnalysis'] = df_['WorkMethodsFrequencyTimeSeriesAnalysis'].fillna(\"no comment\")\n",
        "df_['WorkChallengeFrequencyPolitics'] = df_['WorkChallengeFrequencyPolitics'].fillna(\"no comment\")\n",
        "df_['WorkChallengeFrequencyUnusedResults'] = df_['WorkChallengeFrequencyUnusedResults'].fillna(\"no comment\")\n",
        "df_['WorkChallengeFrequencyDirtyData'] = df_['WorkChallengeFrequencyDirtyData'].fillna(\"no comment\")\n",
        "df_['WorkChallengeFrequencyExplaining'] = df_['WorkChallengeFrequencyExplaining'].fillna(\"no comment\")\n",
        "df_['WorkChallengeFrequencyTalent'] = df_['WorkChallengeFrequencyTalent'].fillna(\"no comment\")\n",
        "df_['WorkChallengeFrequencyClarity'] = df_['WorkChallengeFrequencyClarity'].fillna(\"no comment\")\n",
        "df_['WorkChallengeFrequencyDataAccess'] = df_['WorkChallengeFrequencyDataAccess'].fillna(\"no comment\")\n",
        "\n",
        "\n",
        "\n",
        "#check the updated nan values\n",
        "df_.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rLnqAHSElSa",
        "outputId": "fc550cf6-f430-4c67-a8c3-6df9d3b70289"
      },
      "source": [
        "#Since Code writer column has only one parameter we can eliminate it\n",
        "df_.drop(['CodeWriter','ID','PastJobTitlesSelect','MLTechniquesSelect','WorkAlgorithmsSelect'], inplace=True, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['no comment' 'Somewhat useful' 'Very useful' 'Not Useful']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaJ9nBpmiRB3"
      },
      "source": [
        "### Polynomial,KNN,Linear approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvPMGB6xiQNs"
      },
      "source": [
        "#RUN THIS CELL FOR NO FILLING, IF YOU WANT TO USE NA FILL USE THE NEXT CELL\n",
        "train=df_\n",
        "#train.drop(['CodeWriter','ID','PastJobTitlesSelect','MLTechniquesSelect','WorkAlgorithmsSelect'], inplace=True, axis=1)\n",
        "#train.drop(['WorkDataVisualizations','WorkInternalVsExternalTools'], inplace=True, axis=1)\n",
        "#features=[\"GenderSelect\",\"Country\",\"Age\",\"EmploymentStatus\",\"CurrentJobTitleSelect\",\"TitleFit\",\"CurrentEmployerType\",\"MajorSelect\",\"Tenure\",\"EmployerSize\",\"WorkProductionFrequency\",\"WorkMLTeamSeatSelect\",\"RemoteWork\",\"JobSatisfaction\"]\n",
        "#train['CompensationScore'].fillna(train['CompensationScore'].mode()[0], inplace=True)\n",
        "#train['CompensationScore'].fillna((train['CompensationScore'].mean()), inplace=True)\n",
        "#train['RemoteWork'].fillna((train['RemoteWork'].mean()), inplace=True)\n",
        "#train['RemoteWork'].fillna(train['RemoteWork'].mode()[0], inplace=True)\n",
        "\n",
        "features =['Age',\n",
        " 'CurrentJobTitleSelect',\n",
        " 'TitleFit',\n",
        " 'RemoteWork',\n",
        " 'WorkMLTeamSeatSelect',\n",
        " 'CurrentEmployerType',\n",
        " 'Tenure',\n",
        " 'EmployerIndustry',\n",
        " 'FormalEducation','JobSatisfaction']\n",
        "selected_train = train[features]\n",
        "df = selected_train.dropna()\n",
        "\n",
        "features.remove(\"JobSatisfaction\")\n",
        "X = df.drop('JobSatisfaction', axis = 1)\n",
        "y = df['JobSatisfaction']\n",
        "\n",
        "# Convert categorical values to numbers\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "categories = features\n",
        "one_hot = OneHotEncoder()\n",
        "encoder = ColumnTransformer([('one_hot', one_hot, categories)],\n",
        "                                remainder = 'passthrough')\n",
        "\n",
        "X = encoder.fit_transform(X)\n",
        "\n",
        "# Split the transformed data to training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split as 70%-15%-15%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.19, random_state = 42)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
        "\n",
        "print(\"Train data shape:\", X_train.shape, \"Val data shape:\", X_val.shape, \"Test data shape:\", X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I0GrPsxivvu"
      },
      "source": [
        "the_data=df_\n",
        "the_data['Age'].fillna((the_data['Age'].mean()), inplace=True)\n",
        "the_data['TitleFit'].fillna(the_data['TitleFit'].mode()[0], inplace=True)\n",
        "the_data['GenderSelect'].fillna(the_data['GenderSelect'].mode()[0], inplace=True)\n",
        "the_data['Country'].fillna(the_data['Country'].mode()[0], inplace=True)\n",
        "the_data['EmploymentStatus'].fillna(the_data['EmploymentStatus'].mode()[0], inplace=True)\n",
        "the_data['EmployerSize'].fillna(the_data['EmployerSize'].mode()[0], inplace=True)\n",
        "the_data['WorkProductionFrequency'].fillna(the_data['WorkProductionFrequency'].mode()[0], inplace=True)\n",
        "the_data['WorkMLTeamSeatSelect'].fillna(the_data['WorkMLTeamSeatSelect'].mode()[0], inplace=True)\n",
        "the_data['RemoteWork'].fillna(the_data['RemoteWork'].mode()[0], inplace=True)\n",
        "\n",
        "the_data['CurrentJobTitleSelect'].fillna(the_data['CurrentJobTitleSelect'].mode()[0], inplace=True)\n",
        "the_data['CurrentEmployerType'].fillna(the_data['CurrentEmployerType'].mode()[0], inplace=True)\n",
        "the_data['FormalEducation'].fillna(the_data['FormalEducation'].mode()[0], inplace=True)\n",
        "the_data['MajorSelect'].fillna(the_data['MajorSelect'].mode()[0], inplace=True)\n",
        "the_data['RemoteWork'].fillna(the_data['RemoteWork'].mode()[0], inplace=True)\n",
        "the_data['Tenure'].fillna(the_data['Tenure'].mode()[0], inplace=True)\n",
        "\n",
        "train=the_data\n",
        "\n",
        "train.drop(['CodeWriter','ID','PastJobTitlesSelect','MLTechniquesSelect','WorkAlgorithmsSelect'], inplace=True, axis=1)\n",
        "train.drop(['WorkDataVisualizations','WorkInternalVsExternalTools'], inplace=True, axis=1)\n",
        "#features=[\"GenderSelect\",\"Country\",\"Age\",\"EmploymentStatus\",\"CurrentJobTitleSelect\",\"TitleFit\",\"CurrentEmployerType\",\"MajorSelect\",\"Tenure\",\"EmployerSize\",\"WorkProductionFrequency\",\"WorkMLTeamSeatSelect\",\"RemoteWork\",\"JobSatisfaction\"]\n",
        "features=[\n",
        " 'CurrentJobTitleSelect',\n",
        " 'TitleFit',\n",
        " 'WorkMLTeamSeatSelect',\n",
        " 'Tenure',\n",
        " 'EmployerIndustry',\n",
        " 'FormalEducation']\n",
        "selected_train = train[features]\n",
        "df = selected_train.dropna()\n",
        "\n",
        "features.remove(\"JobSatisfaction\")\n",
        "X = df.drop('JobSatisfaction', axis = 1)\n",
        "y = df['JobSatisfaction']\n",
        "\n",
        "# Convert categorical values to numbers\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "categories = features\n",
        "one_hot = OneHotEncoder()\n",
        "encoder = ColumnTransformer([('one_hot', one_hot, categories)],\n",
        "                                remainder = 'passthrough')\n",
        "\n",
        "X = encoder.fit_transform(X)\n",
        "\n",
        "# Split the transformed data to training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split as 70%-15%-15%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
        "\n",
        "print(\"Train data shape:\", X_train.shape, \"Val data shape:\", X_val.shape, \"Test data shape:\", X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofcU_g4ejUDU"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#############\n",
        "#POLYNOMIAL\n",
        "#############\n",
        "pol_train_error = []\n",
        "pol_valid_error = []\n",
        "\n",
        "for my_degree in [1]:\n",
        "  model = Pipeline([('poly', PolynomialFeatures(degree=my_degree)),('linear', LinearRegression(fit_intercept=False))])\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  train_pred = model.predict(X_train)\n",
        "  val_pred = model.predict(X_val)\n",
        "\n",
        "  mse_train = mean_squared_error(train_pred, y_train, squared = False)\n",
        "  mse_val = mean_squared_error(val_pred, y_val, squared = False)\n",
        "  \n",
        "  pol_train_error.append(mse_train)\n",
        "  pol_valid_error.append(mse_val)\n",
        "\n",
        "print(pol_train_error,pol_valid_error)\n",
        "model = Pipeline([('poly', PolynomialFeatures(degree=1)),('linear', LinearRegression(fit_intercept=False))])\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "mse_test = mean_squared_error(y_pred, y_val, squared = False)\n",
        "print(mse_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCiktQ-qjh5u"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#######\n",
        "#KNN\n",
        "#######\n",
        "train_error = []\n",
        "valid_error = []\n",
        "\n",
        "for neighbors in [5,10,20,25,28,35,40,50,200,300,500]:\n",
        "  model = KNeighborsRegressor(n_neighbors=neighbors,)\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  train_pred = model.predict(X_train)\n",
        "  val_pred = model.predict(X_val)\n",
        "\n",
        "  mse_train = mean_squared_error(train_pred, y_train, squared = False)\n",
        "  mse_val = mean_squared_error(val_pred, y_val, squared = False)\n",
        "  \n",
        "  train_error.append(mse_train)\n",
        "  valid_error.append(mse_val)\n",
        "\n",
        "print(valid_error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THRwKAn6jnTs"
      },
      "source": [
        "model = KNeighborsRegressor(n_neighbors=120,)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "test_pred = model.predict(X_test)\n",
        "mse_test = mean_squared_error(test_pred, y_test, squared = False)\n",
        "print(mse_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-k7V1KGjsNs"
      },
      "source": [
        "##################\n",
        "#LINEAR REGRESSION\n",
        "##################\n",
        "\n",
        "#VALIDATION\n",
        "reg = LinearRegression().fit(X_train, y_train)\n",
        "train_pred = reg.predict(X_train)\n",
        "val_pred = reg.predict(X_val)\n",
        "mse_val = mean_squared_error(val_pred, y_val, squared = False)\n",
        "print(mse_val)\n",
        "\n",
        "#TEST\n",
        "reg = LinearRegression().fit(X_train, y_train)\n",
        "test_pred = reg.predict(X_test)\n",
        "mse_test = mean_squared_error(test_pred, y_test, squared = False)\n",
        "test_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOOjwXZ4G6Y4"
      },
      "source": [
        "# Preprocessing 2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaM-UF83u_wJ"
      },
      "source": [
        "#drop the column if na values are more than half of the rows\n",
        "for column in df_:\n",
        "  if df_[column].isna().sum() > 5528/2:\n",
        "    df_ = df_.drop([column], axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DU__MevVg7e"
      },
      "source": [
        "#drop the columns with more than 1000 features\n",
        "df_.drop(['CodeWriter','ID','PastJobTitlesSelect','MLTechniquesSelect','WorkAlgorithmsSelect'], inplace=True, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoELTdJckiU3"
      },
      "source": [
        "\n",
        "for clm in df_:\n",
        "  if df_[clm].dtypes == 'object':\n",
        "    df_[clm] = df_[clm].fillna(df_[clm].mode().iloc[0]) #majority voting"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1_PaboaH6gt",
        "outputId": "16e7db43-09e7-4fbb-a50c-7dfee556e068"
      },
      "source": [
        "df_.isna().sum() #display the number of missing values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GenderSelect                                 0\n",
              "Country                                      0\n",
              "Age                                         68\n",
              "EmploymentStatus                             0\n",
              "CurrentJobTitleSelect                        0\n",
              "TitleFit                                     0\n",
              "CurrentEmployerType                          0\n",
              "MLToolNextYearSelect                         0\n",
              "MLMethodNextYearSelect                       0\n",
              "LanguageRecommendationSelect                 0\n",
              "LearningPlatformUsefulnessKaggle             0\n",
              "LearningPlatformUsefulnessCourses            0\n",
              "LearningPlatformUsefulnessSO                 0\n",
              "DataScienceIdentitySelect                    0\n",
              "FormalEducation                              0\n",
              "MajorSelect                                  0\n",
              "Tenure                                       0\n",
              "MLSkillsSelect                               0\n",
              "EmployerIndustry                             0\n",
              "EmployerSize                                 0\n",
              "WorkProductionFrequency                      0\n",
              "WorkToolsFrequencyPython                     0\n",
              "WorkToolsFrequencyR                          0\n",
              "WorkToolsFrequencySQL                        0\n",
              "WorkMethodsFrequencyCross-Validation         0\n",
              "WorkMethodsFrequencyDataVisualization        0\n",
              "WorkMethodsFrequencyLogisticRegression       0\n",
              "WorkChallengeFrequencyDirtyData              0\n",
              "CompensationScore                         1156\n",
              "WorkDataVisualizations                       0\n",
              "WorkInternalVsExternalTools                  0\n",
              "WorkMLTeamSeatSelect                         0\n",
              "RemoteWork                                   0\n",
              "JobSatisfaction                              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRnpu34qH1w0"
      },
      "source": [
        "Predict the missing values in Age and CompensationScore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwrlwpUuHx30"
      },
      "source": [
        "#predict CompensationScore\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#exclude nan rows \n",
        "df_cs = df_.dropna()\n",
        "y = df_cs['CompensationScore']\n",
        "X = df_cs.drop(['CompensationScore'],axis=1,inplace=False)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X,y,random_state = 25,test_size = 0.20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xUnQMjL6mL1"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t5lgIr13qby"
      },
      "source": [
        "**Find Most Correlated Columns**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVhhhBDY3u-B"
      },
      "source": [
        "#predict CompensationScore\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#exclude nan rows of Employment Status column\n",
        "df_cs = df_le.dropna()\n",
        "y = df_cs['JobSatisfaction']\n",
        "X = df_cs.drop(['JobSatisfaction'],axis=1,inplace=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6M3hAYc36X7"
      },
      "source": [
        "X.corrwith(y).abs().sort_values()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tKMEsyp3ohI"
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {'max_depth':[3,4,5,6,7], \n",
        "              'learning_rate':[0.1,0.01,0.001,0.0001],\n",
        "              'n_estimators':[10,20,50,100,150,200]}\n",
        "\n",
        "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
        "\n",
        "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
        "\n",
        "clf = GridSearchCV(xg_reg, parameters, scoring='neg_root_mean_squared_error')\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X,y,random_state = 25,test_size = 0.20)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "preds = clf.predict(X_val)\n",
        "rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
        "print(\"RMSE: %f\" % (rmse))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9mA_Wvt9KaW"
      },
      "source": [
        "Drop uncorrelated features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA5Y8B9P7veX"
      },
      "source": [
        "df_reduced = df_le.copy()\n",
        "df_reduced = df_reduced.drop(['WorkMethodsFrequencyDataVisualization'],axis=1,inplace=False)\n",
        "df_reduced = df_reduced.drop(['WorkToolsFrequencyR'],axis=1,inplace=False)\n",
        "df_reduced = df_reduced.drop(['LearningPlatformUsefulnessCourses'],axis=1,inplace=False)\n",
        "df_reduced = df_reduced.drop(['LanguageRecommendationSelect'],axis=1,inplace=False)\n",
        "df_reduced = df_reduced.drop(['MLToolNextYearSelect'],axis=1,inplace=False)\n",
        "df_reduced = df_reduced.drop(['WorkToolsFrequencySQL'],axis=1,inplace=False)\n",
        "df_reduced = df_reduced.drop(['CompensationScore'],axis=1,inplace=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-clHtOR_AGI"
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {'max_depth':[3,4,5,6,7], \n",
        "              'learning_rate':[0.1,0.01,0.001,0.0001],\n",
        "              'n_estimators':[10, 20, 50,100,150,200]}\n",
        "\n",
        "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
        "\n",
        "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
        "\n",
        "clf = GridSearchCV(xg_reg, parameters, scoring='neg_root_mean_squared_error')\n",
        "\n",
        "y = df_reduced['JobSatisfaction']\n",
        "X = df_reduced.drop(['JobSatisfaction'],axis=1,inplace=False)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X,y,random_state = 25,test_size = 0.20)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "preds = clf.predict(X_val)\n",
        "rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
        "print(\"RMSE: %f\" % (rmse))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCebT01m6a-M"
      },
      "source": [
        "Even though the performance improved, a direct relationship between the target (JobSatisfaction) and other features correlation can not be assumed as an identifier for the usefulness of the features. Therefore, another approach for the feature selection is taken."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzZDU2jfEnK7"
      },
      "source": [
        "**Iterating over features after initial filtering**\n",
        "\n",
        "After initially checking the unique number of values in each column as well as the NaN numbers, we come up with thresholds to filter the attributes; in order to escape the curse of dimensionality and have minimum edit in the training data in general to keep the data unbiased. As thresholds, we eliminated the features that have either more than roughly 10-11% missing instances or have more than 70 unique values (since we will need one hot encoding in the features). With addition of the domain experience, we selected 15 features which were hypothesized to be most useful. Then, since we were able to decrease the number of features, we were able to iterate through each combination of the features to come up with the best set, where the models would be able to created with the set that gave the minimum RMSE with cross validation and further optimized for hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLSzFL6jHqD-"
      },
      "source": [
        "import random\n",
        "random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9YGRbwyHiid"
      },
      "source": [
        "import pandas as pd\n",
        "sheet = 'Sheet1'\n",
        "train = pd.read_excel(\"/content/train.xlsx\",sheet_name = sheet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt6KtVBXHwtu"
      },
      "source": [
        "train.nunique() ## to see the number unique values in each column to escape curse of dimensionality after encoding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vuM_7uoH7ZT"
      },
      "source": [
        "train.isnull().sum() ## to see the number of NaN in each column to reduce the loss of data and have smallest bias if majority voting"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m72acHs4JVsv"
      },
      "source": [
        "features = [\"GenderSelect\",\"Country\",\"Age\",\"EmploymentStatus\",\"CurrentJobTitleSelect\",\"TitleFit\",\"CurrentEmployerType\", \"FormalEducation\",\"MajorSelect\", \"Tenure\",\"EmployerIndustry\",\"EmployerSize\",\"WorkProductionFrequency\",\"WorkMLTeamSeatSelect\",\"RemoteWork\"]\n",
        "## remaining features after filtering by thresholds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qTZ9MN6IIab"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import itertools\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "already_included =[\"JobSatisfaction\"] \n",
        "features_comb = list(set(features) - set(already_included))\n",
        "pol_valid_error=[]\n",
        "\n",
        "total_comb = 2**len(features)\n",
        "print(\"Total amount of combinations to check is \",total_comb, \"\\nSearch starting now to find best combination for Ridge Regression.\\n\\n\",sep=\"\")\n",
        "\n",
        "i=0\n",
        "for L in range(1, len(features_comb)+1): ## iterating through all possible combinations of features\n",
        "  for subset in itertools.combinations(features_comb, L):\n",
        "    i=i+1\n",
        "    if (i%1000==0) or i== total_comb:\n",
        "      print(i,\"combinations are complete.\")\n",
        "    total_set = list(subset) + already_included\n",
        "    final_train = train[total_set]\n",
        "    final_train = final_train.dropna() #dropping NaN values in order to keep the data as original as possible in training\n",
        "    X = final_train.drop('JobSatisfaction', axis = 1) # we lost small amount of data so dropna was feasible rather than mode or m.voting\n",
        "    y = final_train['JobSatisfaction']\n",
        "    total_set.remove(\"JobSatisfaction\")\n",
        "    \n",
        "    if \"Age\" in total_set: ## not encoding since it is already numeric feature \n",
        "      total_set.remove(\"Age\")\n",
        "    \n",
        "    categories = total_set\n",
        "    one_hot = OneHotEncoder()\n",
        "    encoder = ColumnTransformer([('one_hot', one_hot, categories)],remainder = 'passthrough')\n",
        "    X = encoder.fit_transform(X)\n",
        "    model = Ridge(alpha=1)\n",
        "    scores = cross_val_score(model, X, y, cv=5, scoring=\"neg_root_mean_squared_error\") ##scores from cross validation with 5fold\n",
        "    score = scores.mean()\n",
        "    pol_valid_error.append(score) ## each score mean for combinations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdTklyucI9qN"
      },
      "source": [
        "my_list = []\n",
        "for L in range(1, len(features_comb)+1):\n",
        "  for subset in itertools.combinations(features_comb, L):\n",
        "    my_list.append(subset)\n",
        "\n",
        "my_list[pol_valid_error.index(max(pol_valid_error))] ## the combination of features with the smallest error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T_5VOr94oec"
      },
      "source": [
        "# Predicting RemoteWork Feature with SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfCOIZLKv_Yu"
      },
      "source": [
        "According to the insights of the data, RemoteWork feature was essential since the distribution of it was significanatly different in test and train data. Therefore, instead of dropping NaN rows of the RemoteWork, we used SVM and Logistic Regression to predict it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9XP9NbQ-yNs"
      },
      "source": [
        "features0 = ['Age',\n",
        " 'CurrentJobTitleSelect',\n",
        " 'TitleFit',\n",
        " 'WorkMLTeamSeatSelect',\n",
        " 'Country',\n",
        " 'CurrentEmployerType',\n",
        " 'WorkProductionFrequency',\n",
        " 'GenderSelect',\n",
        " 'FormalEducation']\n",
        "features = ['Age',\n",
        "  'CurrentJobTitleSelect',\n",
        "  'TitleFit',\n",
        "  'RemoteWork',\n",
        "  'WorkMLTeamSeatSelect',\n",
        "  'Country',\n",
        "  'CurrentEmployerType',\n",
        "  'WorkProductionFrequency',\n",
        "  'GenderSelect',\n",
        "  'FormalEducation']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLNpe9h840DW"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn import svm\n",
        "Cs = [1,1.2,1.3,1.5,1.7,1.8,2, 2.2, 2.4, 2.8, 3, 3.2, 3.4, 3.6, 3.8, 4, 4.5, 5, 4.7, 4.8, 5.5, 6, 10, 20,50,100, 200,300,500,1000]\n",
        "\n",
        "scores_svm = []\n",
        "for c in Cs:\n",
        "  train = df_\n",
        "  the_data = train[features0+['RemoteWork']+[\"JobSatisfaction\"]]\n",
        "  \n",
        "  the_data['Age'].fillna((the_data['Age'].mean()), inplace=True)\n",
        "  #the_data['RemoteWork'].fillna(the_data['RemoteWork'].mode()[0], inplace=True)\n",
        "  the_data['CurrentJobTitleSelect'].fillna(the_data['CurrentJobTitleSelect'].mode()[0], inplace=True)\n",
        "  the_data['TitleFit'].fillna(the_data['TitleFit'].mode()[0], inplace=True)\n",
        "  the_data['GenderSelect'].fillna(the_data['GenderSelect'].mode()[0], inplace=True)\n",
        "  the_data['Country'].fillna(the_data['Country'].mode()[0], inplace=True)\n",
        "  the_data['WorkProductionFrequency'].fillna(the_data['WorkProductionFrequency'].mode()[0], inplace=True)\n",
        "  the_data['WorkMLTeamSeatSelect'].fillna(the_data['WorkMLTeamSeatSelect'].mode()[0], inplace=True)\n",
        "  the_data['CurrentEmployerType'].fillna(the_data['CurrentEmployerType'].mode()[0], inplace=True)\n",
        "  the_data['FormalEducation'].fillna(the_data['FormalEducation'].mode()[0], inplace=True)\n",
        "  train=the_data\n",
        "  #predict RemoteWork\n",
        "  \n",
        "\n",
        "  #exclude nan rows of RemoteWork column\n",
        "  df_rw = train.dropna()\n",
        "  X = df_rw.drop('RemoteWork',axis=1)\n",
        "  y = df_rw['RemoteWork']\n",
        "  categories = features0\n",
        "  one_hot = OneHotEncoder(handle_unknown='ignore')\n",
        "  encoder = ColumnTransformer([('one_hot', one_hot, categories)],remainder = 'passthrough')\n",
        "  X = encoder.fit_transform(X)\n",
        "\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X,y,random_state = 25,test_size = 0.20)\n",
        "  \n",
        "  clf = svm.SVC(C=c)\n",
        "  clf.fit(X_train, y_train)\n",
        "  preds = clf.predict(X_val)\n",
        "  #predict na remote work\n",
        "  rw_cats = ['Sometimes','Rarely','Always','Never','Most of the time',\"Don't know\"]\n",
        "  na_count = 0\n",
        "  for i, row in the_data.iterrows():\n",
        "    if row['RemoteWork'] not in rw_cats:#math.isnan(row['RemoteWork']):\n",
        "      r = pd.DataFrame(row.drop(['RemoteWork'], inplace=False))\n",
        "      \n",
        "      r = r.T #pd.DataFrame(np.array(r).reshape(1, -1))\n",
        "      xx = encoder.transform(r)\n",
        "      predicted_score = clf.predict( xx )\n",
        "      the_data.at[i,'RemoteWork'] = str(predicted_score[0])\n",
        "      \n",
        "      na_count += 1\n",
        "\n",
        "  \n",
        "  X = the_data.drop('JobSatisfaction', axis = 1)\n",
        "  y = the_data['JobSatisfaction']\n",
        "\n",
        "\n",
        "\n",
        "  categories = features\n",
        "  one_hot = OneHotEncoder(handle_unknown='ignore')\n",
        "  encoder = ColumnTransformer([('one_hot', one_hot, categories)],remainder = 'passthrough')\n",
        "  X = encoder.fit_transform(X)\n",
        "  model = Ridge(alpha=40)\n",
        "  scores = cross_val_score(model, X, y, cv=50, scoring=\"neg_root_mean_squared_error\")\n",
        "  score = scores.mean()\n",
        "  scores_svm.append(score)\n",
        "  print('Score:', score, 'C= ', c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deOr3eSp4uvk"
      },
      "source": [
        "# Predicting RemoteWork Feature with Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPU1QRig-4bH"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "Cs = [1,1.2,1.3,1.5,1.7,1.8,2, 2.2, 2.4, 2.8, 3, 3.2, 3.4, 3.6, 3.8, 4, 4.5, 5, 4.7, 4.8, 5.5, 6, 10, 20,50,100, 200,300,500,1000]\n",
        "\n",
        "scores_lg = []\n",
        "for c in Cs:\n",
        "  train = df_\n",
        "  the_data = train[features0+['RemoteWork']+[\"JobSatisfaction\"]]\n",
        "  \n",
        "  the_data['Age'].fillna((the_data['Age'].mean()), inplace=True)\n",
        "  the_data['CurrentJobTitleSelect'].fillna(the_data['CurrentJobTitleSelect'].mode()[0], inplace=True)\n",
        "  the_data['TitleFit'].fillna(the_data['TitleFit'].mode()[0], inplace=True)\n",
        "  the_data['GenderSelect'].fillna(the_data['GenderSelect'].mode()[0], inplace=True)\n",
        "  the_data['Country'].fillna(the_data['Country'].mode()[0], inplace=True)\n",
        "  the_data['WorkProductionFrequency'].fillna(the_data['WorkProductionFrequency'].mode()[0], inplace=True)\n",
        "  the_data['WorkMLTeamSeatSelect'].fillna(the_data['WorkMLTeamSeatSelect'].mode()[0], inplace=True)\n",
        "  the_data['CurrentEmployerType'].fillna(the_data['CurrentEmployerType'].mode()[0], inplace=True)\n",
        "  the_data['FormalEducation'].fillna(the_data['FormalEducation'].mode()[0], inplace=True)\n",
        "  train=the_data\n",
        "  \n",
        "  df_rw = train.dropna()\n",
        "  X = df_rw.drop('RemoteWork',axis=1)\n",
        "  y = df_rw['RemoteWork']\n",
        "  categories = features0\n",
        "  one_hot = OneHotEncoder(handle_unknown='ignore')\n",
        "  encoder = ColumnTransformer([('one_hot', one_hot, categories)],remainder = 'passthrough')\n",
        "  X = encoder.fit_transform(X)\n",
        "\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X,y,random_state = 25,test_size = 0.20)\n",
        "  \n",
        "  clf = LogisticRegression(C=c)\n",
        "  clf.fit(X_train, y_train)\n",
        "  preds = clf.predict(X_val)\n",
        "  #predict na remote work\n",
        "  rw_cats = ['Sometimes','Rarely','Always','Never','Most of the time',\"Don't know\"]\n",
        "  na_count = 0\n",
        "  for i, row in the_data.iterrows():\n",
        "    if row['RemoteWork'] not in rw_cats:#math.isnan(row['RemoteWork']):\n",
        "      r = pd.DataFrame(row.drop(['RemoteWork'], inplace=False))\n",
        "      \n",
        "      r = r.T #pd.DataFrame(np.array(r).reshape(1, -1))\n",
        "      xx = encoder.transform(r)\n",
        "      predicted_score = clf.predict( xx )\n",
        "      the_data.at[i,'RemoteWork'] = str(predicted_score[0])\n",
        "      \n",
        "      na_count += 1\n",
        "\n",
        "  X = the_data.drop('JobSatisfaction', axis = 1)\n",
        "  y = the_data['JobSatisfaction']\n",
        "\n",
        "\n",
        "\n",
        "  categories = features\n",
        "  one_hot = OneHotEncoder(handle_unknown='ignore')\n",
        "  encoder = ColumnTransformer([('one_hot', one_hot, categories)],remainder = 'passthrough')\n",
        "  X = encoder.fit_transform(X)\n",
        "  model = Ridge(alpha=40)\n",
        "  scores = cross_val_score(model, X, y, cv=50, scoring=\"neg_root_mean_squared_error\")\n",
        "  score = scores.mean()\n",
        "  scores_lg.append(score)\n",
        "  print('Score:', score, 'C= ', c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzlGPKIw-9D0"
      },
      "source": [
        "max(scores_lg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaK8MW81-9iv"
      },
      "source": [
        "max(scores_svm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16UqttC045lB"
      },
      "source": [
        "Prediction of the missing RemoteWork values with SVM outperforms the performance of Logistic Regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsEm780U52MP"
      },
      "source": [
        "# Performance Evaluation of the Data with Predicted RemoteWork Feature on: VGBoost, Ridge Regression, KNN, SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl7FlQ_E_KNz"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn import svm\n",
        "\n",
        "train = df_\n",
        "the_data = train[features0+['RemoteWork']+[\"JobSatisfaction\"]]\n",
        "\n",
        "the_data['Age'].fillna((the_data['Age'].mean()), inplace=True)\n",
        "the_data['CurrentJobTitleSelect'].fillna(the_data['CurrentJobTitleSelect'].mode()[0], inplace=True)\n",
        "the_data['TitleFit'].fillna(the_data['TitleFit'].mode()[0], inplace=True)\n",
        "the_data['GenderSelect'].fillna(the_data['GenderSelect'].mode()[0], inplace=True)\n",
        "the_data['WorkProductionFrequency'].fillna(the_data['WorkProductionFrequency'].mode()[0], inplace=True)\n",
        "the_data['WorkMLTeamSeatSelect'].fillna(the_data['WorkMLTeamSeatSelect'].mode()[0], inplace=True)\n",
        "the_data['CurrentEmployerType'].fillna(the_data['CurrentEmployerType'].mode()[0], inplace=True)\n",
        "the_data['FormalEducation'].fillna(the_data['FormalEducation'].mode()[0], inplace=True)\n",
        "the_data['Country'].fillna(the_data['Country'].mode()[0], inplace=True)\n",
        "train=the_data\n",
        "\n",
        "\n",
        "#exclude nan rows of RemoteWork column\n",
        "df_rw = train.dropna()\n",
        "X = df_rw.drop('RemoteWork',axis=1)\n",
        "y = df_rw['RemoteWork']\n",
        "categories = features0\n",
        "one_hot = OneHotEncoder(handle_unknown='ignore')\n",
        "encoder = ColumnTransformer([('one_hot', one_hot, categories)],remainder = 'passthrough')\n",
        "X = encoder.fit_transform(X)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X,y,random_state = 25,test_size = 0.20)\n",
        "\n",
        "clf = svm.SVC(C=300)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_val)\n",
        "#predict na remote work\n",
        "rw_cats = ['Sometimes','Rarely','Always','Never','Most of the time',\"Don't know\"]\n",
        "na_count = 0\n",
        "for i, row in the_data.iterrows():\n",
        "  if row['RemoteWork'] not in rw_cats:#math.isnan(row['RemoteWork']):\n",
        "    r = pd.DataFrame(row.drop(['RemoteWork'], inplace=False))\n",
        "    \n",
        "    r = r.T #pd.DataFrame(np.array(r).reshape(1, -1))\n",
        "    xx = encoder.transform(r)\n",
        "    predicted_score = clf.predict( xx )\n",
        "    the_data.at[i,'RemoteWork'] = str(predicted_score[0])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDRADe1__L0p"
      },
      "source": [
        "#RIDGE REGRESSION\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "X = the_data.drop(['JobSatisfaction','Age'], axis = 1)\n",
        "y = the_data['JobSatisfaction']\n",
        "\n",
        "features = [\n",
        "  'CurrentJobTitleSelect',\n",
        "  'TitleFit',\n",
        "  'RemoteWork',\n",
        "  'Country',\n",
        "  'WorkMLTeamSeatSelect',\n",
        "  'CurrentEmployerType',\n",
        "  'WorkProductionFrequency',\n",
        "  'GenderSelect',\n",
        "  'FormalEducation']\n",
        "categories = features\n",
        "one_hot = OneHotEncoder(handle_unknown='ignore')\n",
        "encoder = ColumnTransformer([('one_hot', one_hot, categories)],remainder = 'passthrough')\n",
        "X = encoder.fit_transform(X)\n",
        "X = pd.concat([pd.DataFrame(X.todense()), the_data['Age']],axis=1)\n",
        "\n",
        "parameters = {'alpha':[1,5,10,15,25,35,40,45,50,70,100]}\n",
        "\n",
        "model = Ridge(alpha=40)\n",
        "clf = GridSearchCV(model, parameters, scoring='neg_root_mean_squared_error')\n",
        "\n",
        "clf.fit(X,y)\n",
        "\n",
        "print(clf.best_params_)\n",
        "model = Ridge(alpha=35)\n",
        "#model.fit(X,y) \n",
        "\n",
        "\n",
        "scores = cross_val_score(model, X, y, cv=50, scoring=\"neg_root_mean_squared_error\")\n",
        "score = scores.mean()\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzccflmE_Qrm"
      },
      "source": [
        "#SVM\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "X = the_data.drop('JobSatisfaction', axis = 1)\n",
        "y = the_data['JobSatisfaction']\n",
        "\n",
        "features = ['Age',\n",
        "  'CurrentJobTitleSelect',\n",
        "  'TitleFit',\n",
        "  'RemoteWork',\n",
        "  'Country',\n",
        "  'WorkMLTeamSeatSelect',\n",
        "  'CurrentEmployerType',\n",
        "  'WorkProductionFrequency',\n",
        "  'GenderSelect',\n",
        "  'FormalEducation']\n",
        "categories = features\n",
        "one_hot = OneHotEncoder(handle_unknown='ignore')\n",
        "encoder = ColumnTransformer([('one_hot', one_hot, categories)],remainder = 'passthrough')\n",
        "X = encoder.fit_transform(X)\n",
        "\n",
        "\n",
        "parameters = {'C':[1,10,30,40,45,50,70,100],\n",
        "              'degree': [1,2,3,4],\n",
        "              'gamma': ['scale', 'auto']}\n",
        "\n",
        "model = svm.SVR(C=40)\n",
        "clf = GridSearchCV(model, parameters, scoring='neg_root_mean_squared_error')\n",
        "\n",
        "clf.fit(X,y)\n",
        "\n",
        "print(clf.best_params_)\n",
        "\n",
        "model = svm.SVR(C=10,degree=1,gamma='auto')\n",
        "scores = cross_val_score(model, X, y, cv=100, scoring=\"neg_root_mean_squared_error\")\n",
        "score = scores.mean()\n",
        "\n",
        "print(\"RMSE: %f\" % (score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJQjgiTl_dfN"
      },
      "source": [
        "#KNN\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "X = the_data.drop('JobSatisfaction', axis = 1)\n",
        "y = the_data['JobSatisfaction']\n",
        "\n",
        "features = ['Age',\n",
        "  'CurrentJobTitleSelect',\n",
        "  'TitleFit',\n",
        "  'RemoteWork',\n",
        "  'Country',\n",
        "  'WorkMLTeamSeatSelect',\n",
        "  'CurrentEmployerType',\n",
        "  'WorkProductionFrequency',\n",
        "  'GenderSelect',\n",
        "  'FormalEducation']\n",
        "categories = features\n",
        "one_hot = OneHotEncoder(handle_unknown='ignore')\n",
        "encoder = ColumnTransformer([('one_hot', one_hot, categories)],remainder = 'passthrough')\n",
        "X = encoder.fit_transform(X)\n",
        "model = Ridge(alpha=40)\n",
        "scores = cross_val_score(model, X, y, cv=50, scoring=\"neg_root_mean_squared_error\")\n",
        "score = scores.mean()\n",
        "scores_lg.append(score)\n",
        "\n",
        "\n",
        "parameters = {'n_neighbors':[28,35,40,45,50,55,60,65,70,75,80,85,90,100,200,300,500],\n",
        "              'weights': ['uniform','distance']}\n",
        "\n",
        "model = KNeighborsRegressor(n_neighbors=5)\n",
        "clf = GridSearchCV(model, parameters, scoring='neg_root_mean_squared_error')\n",
        "clf.fit(X,y)\n",
        "print(clf.best_params_ )\n",
        "\n",
        "model = KNeighborsRegressor(n_neighbors=55,weights='uniform')\n",
        "scores = cross_val_score(model, X, y, cv=50, scoring=\"neg_root_mean_squared_error\")\n",
        "score = scores.mean()\n",
        "\n",
        "print(\"RMSE: %f\" % (score))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXJXVoGK_nbm"
      },
      "source": [
        "#XGBoost\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {'max_depth':[3,4,5,6,7], \n",
        "              'learning_rate':[0.1,0.01,0.001,0.0001],\n",
        "              'n_estimators':[10,20,50,100,150,200]}\n",
        "\n",
        "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
        "\n",
        "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
        "\n",
        "clf = GridSearchCV(xg_reg, parameters, scoring='neg_root_mean_squared_error')\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X,y,random_state = 25,test_size = 0.20)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "preds = clf.predict(X_val)\n",
        "rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
        "print(\"RMSE: %f\" % (rmse))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWb6PtsbviCi"
      },
      "source": [
        "One prediction submitted to Kaggle was obtained by the model above. The result was: 2.01350."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_d6DEHn5G_s"
      },
      "source": [
        "# Creating Features with Dimensionality Reduction: t-SNE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTELTZj6Ak3R"
      },
      "source": [
        "#PREPROCESSING\n",
        "from sklearn.manifold import TSNE\n",
        "df_ = pd.read_excel(join(path_prefix, fname))\n",
        "\n",
        "for column in df_:\n",
        "  if df_[column].isna().sum() > 5528/2 or column=='CompensationScore':\n",
        "    df_ = df_.drop([column], axis=1)\n",
        "\n",
        "df_['Age'].fillna((df_['Age'].mean()), inplace=True)\n",
        "df_['TitleFit'].fillna(df_['TitleFit'].mode()[0], inplace=True)\n",
        "df_['GenderSelect'].fillna(df_['GenderSelect'].mode()[0], inplace=True)\n",
        "df_['Country'].fillna(df_['Country'].mode()[0], inplace=True)\n",
        "df_['EmploymentStatus'].fillna(df_['EmploymentStatus'].mode()[0], inplace=True)\n",
        "df_['EmployerSize'].fillna(df_['EmployerSize'].mode()[0], inplace=True)\n",
        "df_['WorkProductionFrequency'].fillna(df_['WorkProductionFrequency'].mode()[0], inplace=True)\n",
        "df_['WorkMLTeamSeatSelect'].fillna(df_['WorkMLTeamSeatSelect'].mode()[0], inplace=True)\n",
        "df_['RemoteWork'].fillna(df_['RemoteWork'].mode()[0], inplace=True)\n",
        "\n",
        "df_['CurrentJobTitleSelect'].fillna(df_['CurrentJobTitleSelect'].mode()[0], inplace=True)\n",
        "df_['CurrentEmployerType'].fillna(df_['CurrentEmployerType'].mode()[0], inplace=True)\n",
        "df_['FormalEducation'].fillna(df_['FormalEducation'].mode()[0], inplace=True)\n",
        "df_['MajorSelect'].fillna(df_['MajorSelect'].mode()[0], inplace=True)\n",
        "df_['RemoteWork'].fillna('df_['RemoteWork'].mode()[0]', inplace=True)\n",
        "df_['Tenure'].fillna(df_['Tenure'].mode()[0], inplace=True)\n",
        "\n",
        "for clm in df_:\n",
        "  if df_[clm].dtypes == 'object' and clm != 'RemoteWork':\n",
        "    df_[clm] = df_[clm].fillna(df_[clm].mode().iloc[0]) #majority voting\n",
        "\n",
        "#drop the columns with more than 1000 features\n",
        "df_.drop(['CodeWriter','ID','PastJobTitlesSelect','MLTechniquesSelect','WorkAlgorithmsSelect'], inplace=True, axis=1)\n",
        "\n",
        "#exclude nan rows \n",
        "df_rw = df_.dropna()\n",
        "X = df_rw.drop('RemoteWork',axis=1)\n",
        "y = df_rw['RemoteWork']\n",
        "\n",
        "all_ftrs = list(df_.columns)\n",
        "all_ftrs.remove('RemoteWork')\n",
        "categories = all_ftrs\n",
        "one_hot = OneHotEncoder(handle_unknown='ignore')\n",
        "encoder = ColumnTransformer([('one_hot', one_hot, categories)],remainder = 'passthrough')\n",
        "X = encoder.fit_transform(X)\n",
        "\n",
        "#predict na remote work\n",
        "rw_cats = ['Sometimes','Rarely','Always','Never','Most of the time',\"Don't know\"]\n",
        "na_count = 0\n",
        "for i, row in df_.iterrows():\n",
        "  if row['RemoteWork'] not in rw_cats:#math.isnan(row['RemoteWork']):\n",
        "    r = pd.DataFrame(row.drop(['RemoteWork'], inplace=False))\n",
        "    \n",
        "    r = r.T #pd.DataFrame(np.array(r).reshape(1, -1))\n",
        "    xx = encoder.transform(r)\n",
        "    predicted_score = clf.predict( xx )\n",
        "    df_.at[i,'RemoteWork'] = str(predicted_score[0])\n",
        "\n",
        "\n",
        "#check the updated nan values\n",
        "df_.isna().sum()\n",
        "\n",
        "all = list(df_.columns)\n",
        "all.remove('JobSatisfaction')\n",
        "categories = all\n",
        "one_hot = OneHotEncoder(handle_unknown='ignore')\n",
        "encoder = ColumnTransformer([('one_hot', one_hot, categories)],remainder = 'passthrough')\n",
        "X = df_.drop('JobSatisfaction', axis = 1)\n",
        "X = encoder.fit_transform(X)\n",
        "\n",
        "y = df_['JobSatisfaction']\n",
        "df_tsne_extension = pd.concat([pd.DataFrame(X.todense()), pd.DataFrame(X_embedded)], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LO3aMCRAs9m"
      },
      "source": [
        "#RIDGE REGRESSION with extended df\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import Ridge\n",
        "X = df_tsne_extension\n",
        "y = the_data['JobSatisfaction']\n",
        "\n",
        "model = Ridge(alpha=40)\n",
        "\n",
        "parameters = {'alpha':[1,5,10,15,25,35,40,45,50,70,100]}\n",
        "\n",
        "model = Ridge(alpha=40)\n",
        "clf = GridSearchCV(model, parameters, scoring='neg_root_mean_squared_error')\n",
        "clf.fit(X,y)\n",
        "\n",
        "clf.best_params_\n",
        "\n",
        "model = Ridge(alpha=100)\n",
        "scores = cross_val_score(model, X, y, cv=50, scoring=\"neg_root_mean_squared_error\")\n",
        "score = scores.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zmdRT-KA14z"
      },
      "source": [
        "#RIDGE REGRESSION with tsne data\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import Ridge\n",
        "X = X_embedded\n",
        "y = the_data['JobSatisfaction']\n",
        "\n",
        "model = Ridge(alpha=40)\n",
        "\n",
        "parameters = {'alpha':[1,5,10,15,25,35,40,45,50,70,100,150,200,250,300,500,1000,20000,30000,50000,100000,300000,600000]}\n",
        "\n",
        "model = Ridge(alpha=40)\n",
        "clf = GridSearchCV(model, parameters, scoring='neg_root_mean_squared_error')\n",
        "clf.fit(X,y)\n",
        "clf.best_params_\n",
        "model = Ridge(alpha=10000)\n",
        "scores = cross_val_score(model, X, y, cv=50, scoring=\"neg_root_mean_squared_error\")\n",
        "score = scores.mean()\n",
        "print(\"RMSE: %f\" % (score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yIJE4ZhA-dg"
      },
      "source": [
        "#RIDGE REGRESSION with picked columns and tsne data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn import svm\n",
        "features0 = ['Age',\n",
        " 'CurrentJobTitleSelect',\n",
        " 'TitleFit',\n",
        " 'WorkMLTeamSeatSelect',\n",
        " 'CurrentEmployerType',\n",
        " 'WorkProductionFrequency',\n",
        " 'GenderSelect',\n",
        " 'Country',\n",
        " 'FormalEducation']\n",
        "\n",
        "df_ = pd.read_excel(join(path_prefix, fname))\n",
        "train = df_\n",
        "the_data = train[features0+['RemoteWork']+[\"JobSatisfaction\"]]\n",
        "\n",
        "the_data['Age'].fillna((the_data['Age'].mean()), inplace=True)\n",
        "the_data['CurrentJobTitleSelect'].fillna(the_data['CurrentJobTitleSelect'].mode()[0], inplace=True)\n",
        "the_data['TitleFit'].fillna(the_data['TitleFit'].mode()[0], inplace=True)\n",
        "the_data['GenderSelect'].fillna(the_data['GenderSelect'].mode()[0], inplace=True)\n",
        "the_data['WorkProductionFrequency'].fillna(the_data['WorkProductionFrequency'].mode()[0], inplace=True)\n",
        "the_data['WorkMLTeamSeatSelect'].fillna(the_data['WorkMLTeamSeatSelect'].mode()[0], inplace=True)\n",
        "the_data['CurrentEmployerType'].fillna(the_data['CurrentEmployerType'].mode()[0], inplace=True)\n",
        "the_data['FormalEducation'].fillna(the_data['FormalEducation'].mode()[0], inplace=True)\n",
        "the_data['Country'].fillna(the_data['Country'].mode()[0], inplace=True)\n",
        "train=the_data\n",
        "\n",
        "#predict RemoteWork\n",
        "df_rw = train.dropna()\n",
        "X = df_rw.drop('RemoteWork',axis=1)\n",
        "y = df_rw['RemoteWork']\n",
        "categories = features0\n",
        "one_hot = OneHotEncoder(handle_unknown='ignore')\n",
        "encoder = ColumnTransformer([('one_hot', one_hot, categories)],remainder = 'passthrough')\n",
        "X = encoder.fit_transform(X)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X,y,random_state = 25,test_size = 0.20)\n",
        "\n",
        "clf = svm.SVC(C=300)\n",
        "clf.fit(X,y)\n",
        "rw_cats = ['Sometimes','Rarely','Always','Never','Most of the time',\"Don't know\"]\n",
        "na_count = 0\n",
        "for i, row in the_data.iterrows():\n",
        "  if row['RemoteWork'] not in rw_cats:#math.isnan(row['RemoteWork']):\n",
        "    r = pd.DataFrame(row.drop(['RemoteWork'], inplace=False))\n",
        "    \n",
        "    r = r.T #pd.DataFrame(np.array(r).reshape(1, -1))\n",
        "    xx = encoder.transform(r)\n",
        "    predicted_score = clf.predict( xx )\n",
        "    the_data.at[i,'RemoteWork'] = str(predicted_score[0])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DymF2_ZBNvJ"
      },
      "source": [
        "categories = list(the_data.columns)\n",
        "categories.remove('JobSatisfaction')\n",
        "one_hot = OneHotEncoder(handle_unknown='ignore')\n",
        "encoder = ColumnTransformer([('one_hot', one_hot, categories)],remainder = 'passthrough')\n",
        "X = the_data.drop('JobSatisfaction',axis=1)\n",
        "y = the_data['JobSatisfaction']\n",
        "X = encoder.fit_transform(X)\n",
        "data_tsne_extension = pd.concat([pd.DataFrame(X.todense()), pd.DataFrame(X_embedded)], axis=1)\n",
        "\n",
        "model = Ridge(alpha=40)\n",
        "parameters = {'alpha':[1,5,10,15,25,35,40,45,50,70,100,150]}\n",
        "\n",
        "model = Ridge(alpha=40)\n",
        "clf = GridSearchCV(model, parameters, scoring='neg_root_mean_squared_error')\n",
        "clf.fit(X,y)\n",
        "print(clf.best_params_)\n",
        "model = Ridge(alpha=35)\n",
        "scores = cross_val_score(model, X, y, cv=50, scoring=\"neg_root_mean_squared_error\")\n",
        "score = scores.mean()\n",
        "print(\"RMSE: %f\" % (score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4Cx7fNC5JDR"
      },
      "source": [
        "# Creating Features with Dimensionality Reduction: Autoencoders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rCE7qA0BXQ5"
      },
      "source": [
        "#PREPROCESSING\n",
        "from sklearn.manifold import TSNE\n",
        "df_ = pd.read_excel(join(path_prefix, fname))\n",
        "\n",
        "for column in df_:\n",
        "  if df_[column].isna().sum() > 5528/2 or column=='CompensationScore':\n",
        "    df_ = df_.drop([column], axis=1)\n",
        "\n",
        "df_['Age'].fillna((df_['Age'].mean()), inplace=True)\n",
        "df_['TitleFit'].fillna(df_['TitleFit'].mode()[0], inplace=True)\n",
        "df_['GenderSelect'].fillna(df_['GenderSelect'].mode()[0], inplace=True)\n",
        "df_['Country'].fillna(df_['Country'].mode()[0], inplace=True)\n",
        "df_['EmploymentStatus'].fillna(df_['EmploymentStatus'].mode()[0], inplace=True)\n",
        "df_['EmployerSize'].fillna(df_['EmployerSize'].mode()[0], inplace=True)\n",
        "df_['WorkProductionFrequency'].fillna(df_['WorkProductionFrequency'].mode()[0], inplace=True)\n",
        "df_['WorkMLTeamSeatSelect'].fillna(df_['WorkMLTeamSeatSelect'].mode()[0], inplace=True)\n",
        "df_['RemoteWork'].fillna('-', inplace=True)\n",
        "\n",
        "df_['CurrentJobTitleSelect'].fillna(df_['CurrentJobTitleSelect'].mode()[0], inplace=True)\n",
        "df_['CurrentEmployerType'].fillna(df_['CurrentEmployerType'].mode()[0], inplace=True)\n",
        "df_['FormalEducation'].fillna(df_['FormalEducation'].mode()[0], inplace=True)\n",
        "df_['MajorSelect'].fillna(df_['MajorSelect'].mode()[0], inplace=True)\n",
        "df_['RemoteWork'].fillna('-', inplace=True)\n",
        "df_['Tenure'].fillna(df_['Tenure'].mode()[0], inplace=True)\n",
        "\n",
        "for clm in df_:\n",
        "  if df_[clm].dtypes == 'object' and clm != 'RemoteWork':\n",
        "    df_[clm] = df_[clm].fillna(df_[clm].mode().iloc[0]) #majority voting\n",
        "\n",
        "#drop the columns with more than 1000 features\n",
        "df_.drop(['CodeWriter','ID','PastJobTitlesSelect','MLTechniquesSelect','WorkAlgorithmsSelect','RemoteWork'], inplace=True, axis=1)\n",
        "\n",
        "#check the updated nan values\n",
        "df_.isna().sum()\n",
        "\n",
        "features = ['Age',\n",
        "  'CurrentJobTitleSelect',\n",
        "  'TitleFit',\n",
        "  'Country',\n",
        "  'WorkMLTeamSeatSelect',\n",
        "  'CurrentEmployerType',\n",
        "  'WorkProductionFrequency',\n",
        "  'GenderSelect',\n",
        "  'FormalEducation',\n",
        "  'RemoteWork',\n",
        "  'JobSatisfaction']\n",
        "  \n",
        "df_ = pd.read_excel(join(path_prefix, fname))\n",
        "df_ = df_[features]\n",
        "df_['CurrentEmployerType'].fillna(df_['CurrentEmployerType'].mode()[0], inplace=True)\n",
        "df_['Age'].fillna((df_['Age'].mean()), inplace=True)\n",
        "df_['CurrentJobTitleSelect'].fillna(df_['CurrentJobTitleSelect'].mode()[0], inplace=True)\n",
        "df_['TitleFit'].fillna(df_['TitleFit'].mode()[0], inplace=True)\n",
        "df_['GenderSelect'].fillna(df_['GenderSelect'].mode()[0], inplace=True)\n",
        "df_['Country'].fillna(df_['Country'].mode()[0], inplace=True)\n",
        "df_['FormalEducation'].fillna(df_['FormalEducation'].mode()[0], inplace=True)\n",
        "df_['WorkProductionFrequency'].fillna(df_['WorkProductionFrequency'].mode()[0], inplace=True)\n",
        "df_['WorkMLTeamSeatSelect'].fillna(df_['WorkMLTeamSeatSelect'].mode()[0], inplace=True)\n",
        "\n",
        "df_['RemoteWork'].fillna('-', inplace=True)\n",
        "\n",
        "df_.isna().sum()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIlCZ9XbB1Jc"
      },
      "source": [
        "categories = list(df_.columns)\n",
        "categories.remove('JobSatisfaction')\n",
        "categories.remove('Age')\n",
        "\n",
        "one_hot = OneHotEncoder(handle_unknown='ignore')\n",
        "encoder = ColumnTransformer([('one_hot', one_hot, categories)], remainder='passthrough')\n",
        "X = df_.drop(['JobSatisfaction','Age'],axis=1)\n",
        "y = df_['JobSatisfaction']\n",
        "X = encoder.fit_transform(X)\n",
        "X = X.todense()\n",
        "\n",
        "X = pd.concat([pd.DataFrame(X), df_['Age']], axis = 1)\n",
        "INPUT_DIM = X.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chXzEI14CFWa"
      },
      "source": [
        "def GetModel(sigmoid_act: bool=True):\n",
        "  act_func = 'sigmoid' if sigmoid_act else 'elu'\n",
        "  inputs = tf.keras.Input(shape=(INPUT_DIM, ))\n",
        "  x = tf.keras.layers.Dense(512, activation=act_func)(inputs) \n",
        "  x = tf.keras.layers.Dense(256, activation=act_func)(x) \n",
        "  x = tf.keras.layers.Dense(128, activation=act_func)(x) \n",
        "  #x = tf.keras.layers.Dense(64, activation=act_func)(x)\n",
        "  bn = tf.keras.layers.Dense(64, activation=act_func)(x)\n",
        "  #x = tf.keras.layers.Dense(64, activation=act_func)(bn)\n",
        "  x = tf.keras.layers.Dense(128, activation=act_func)(x)\n",
        "  x = tf.keras.layers.Dense(256, activation=act_func)(x)\n",
        "  x = tf.keras.layers.Dense(512, activation=act_func)(x)\n",
        "  x = tf.keras.layers.Dense(INPUT_DIM)(x)\n",
        "\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=[bn, x])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zSPPLUZCHVy"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "autoencoder = GetModel(sigmoid_act=False)\n",
        "autoencoder.compile(loss=[None, tf.keras.losses.MeanSquaredError()], \n",
        "                    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "                    )\n",
        "\n",
        "autoencoder.fit(x=X, y=X,\n",
        "                validation_split=0.1,\n",
        "                batch_size=128,\n",
        "                epochs=1000,\n",
        "                callbacks=[tf.keras.callbacks.EarlyStopping(patience=20,\n",
        "                                                            min_delta=5e-5),\n",
        "                           tf.keras.callbacks.ReduceLROnPlateau(patience=15,\n",
        "                                                                factor=0.75)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srcBEG47CJ5f"
      },
      "source": [
        "X = np.array(X)\n",
        "latent, _ = autoencoder(X, training=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdRGA8HACLo1"
      },
      "source": [
        "model = Ridge(alpha=40)\n",
        "\n",
        "parameters = {'alpha':[1,5,10,15,25,35,40,45,50,70,100,150]}\n",
        "\n",
        "model = Ridge(alpha=40)\n",
        "clf = GridSearchCV(model, parameters, scoring='neg_root_mean_squared_error')\n",
        "clf.fit(np.array(latent),y)\n",
        "clf.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cndsN_a_COX_"
      },
      "source": [
        "model = Ridge(alpha=5)\n",
        "scores = cross_val_score(model, X, y, cv=50, scoring=\"neg_root_mean_squared_error\")\n",
        "score = scores.mean()\n",
        "print(\"RMSE: %f\" % (score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovdTXI8i79xq"
      },
      "source": [
        "# Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQIImRpW8qh0"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "import keras.optimizers \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "y = df_reduced['JobSatisfaction']\n",
        "X = df_reduced.drop(['JobSatisfaction'],axis=1,inplace=False)\n",
        "\n",
        "# create the model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X.shape[1],), name='hidden_layer1'))\n",
        "model.add(Dense(32, activation='relu', name='hidden_layer2'))\n",
        "model.add(Dense(1, kernel_initializer='normal', name='output_layer'))\n",
        "\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
        "\n",
        "# fit method train the model by slicing the data into batches of size batch_size and iterate over the entire dataset for given number of epochs\n",
        "# history holds a record of the loss values and metric values during training\n",
        "history = model.fit(X, y, batch_size=32, epochs=15, #validation_data=(x_val, y_val), \n",
        "                    validation_split = 0.2, #automatically reserve part of the training data for validation\n",
        "                    verbose=1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoXqBcBo8t2m"
      },
      "source": [
        "#Tune optimizers - try 'sgd'\n",
        "\n",
        "# create the model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X.shape[1],), name='hidden_layer1'))\n",
        "model.add(Dense(32, activation='relu', name='hidden_layer2'))\n",
        "model.add(Dense(10, activation='softmax', name='output_layer'))\n",
        "\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer = 'sgd', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
        "\n",
        "history = model.fit(X, y, batch_size=32, epochs=15, #validation_data=(x_val, y_val), \n",
        "                    validation_split = 0.2, #automatically reserve part of the training data for validation\n",
        "                    verbose=1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4MYxlAH8xEA"
      },
      "source": [
        "#Tune layer numbers\n",
        "import tensorflow as tf\n",
        "\n",
        "y = df_reduced['JobSatisfaction']\n",
        "X = df_reduced.drop(['JobSatisfaction'],axis=1,inplace=False)\n",
        "\n",
        "# create the model 4 layers\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(128, activation='relu', input_shape=(X.shape[1],), name='hidden_layer1'))\n",
        "model.add(Dense(64, activation='relu', name='hidden_layer2'))\n",
        "model.add(Dense(32, activation='relu', name='hidden_layer3'))\n",
        "model.add(Dense(1, kernel_initializer='normal', name='output_layer'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
        "\n",
        "# fit method train the model by slicing the data into batches of size batch_size and iterate over the entire dataset for given number of epochs\n",
        "# history holds a record of the loss values and metric values during training\n",
        "history = model.fit(X, y, batch_size=32, epochs=15, #validation_data=(x_val, y_val), \n",
        "                    validation_split = 0.2, #automatically reserve part of the training data for validation\n",
        "                    verbose=1)\n",
        "\n",
        "# create the model 5 layers\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(256, activation='relu', input_shape=(X.shape[1],), name='hidden_layer1'))\n",
        "model.add(Dense(128, activation='relu', name='hidden_layer2'))\n",
        "model.add(Dense(64, activation='relu', name='hidden_layer3'))\n",
        "model.add(Dense(32, activation='relu', name='hidden_layer4'))\n",
        "model.add(Dense(1, kernel_initializer='normal', name='output_layer'))\n",
        "\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
        "\n",
        "# fit method train the model by slicing the data into batches of size batch_size and iterate over the entire dataset for given number of epochs\n",
        "# history holds a record of the loss values and metric values during training\n",
        "history = model.fit(X, y, batch_size=32, epochs=15, #validation_data=(x_val, y_val), \n",
        "                    validation_split = 0.2, #automatically reserve part of the training data for validation\n",
        "                    verbose=1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpQKYDAd83Z1"
      },
      "source": [
        "#Tune neuron numbers\n",
        "import tensorflow as tf\n",
        "\n",
        "y = df_reduced['JobSatisfaction']\n",
        "X = df_reduced.drop(['JobSatisfaction'],axis=1,inplace=False)\n",
        "\n",
        "# create the model \n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(X.shape[1],), name='hidden_layer1'))\n",
        "model.add(Dense(64, activation='relu', name='hidden_layer2'))\n",
        "model.add(Dense(1, kernel_initializer='normal', name='output_layer'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
        "\n",
        "# fit method train the model by slicing the data into batches of size batch_size and iterate over the entire dataset for given number of epochs\n",
        "# history holds a record of the loss values and metric values during training\n",
        "history = model.fit(X, y, batch_size=32, epochs=15, #validation_data=(x_val, y_val), \n",
        "                    validation_split = 0.2, #automatically reserve part of the training data for validation\n",
        "                    verbose=1)\n",
        "\n",
        "# create the model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(X.shape[1],), name='hidden_layer1'))\n",
        "model.add(Dense(32, activation='relu', name='hidden_layer2'))\n",
        "model.add(Dense(1, kernel_initializer='normal', name='output_layer'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
        "\n",
        "# fit method train the model by slicing the data into batches of size batch_size and iterate over the entire dataset for given number of epochs\n",
        "# history holds a record of the loss values and metric values during training\n",
        "history = model.fit(X, y, batch_size=32, epochs=15, #validation_data=(x_val, y_val), \n",
        "                    validation_split = 0.2, #automatically reserve part of the training data for validation\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vR4k-WP87Lb"
      },
      "source": [
        "#Tune batch sizes\n",
        "# create the model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(X.shape[1],), name='hidden_layer1'))\n",
        "model.add(Dense(32, activation='relu', name='hidden_layer2'))\n",
        "model.add(Dense(1, kernel_initializer='normal', name='output_layer'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
        "\n",
        "# fit method train the model by slicing the data into batches of size batch_size and iterate over the entire dataset for given number of epochs\n",
        "# history holds a record of the loss values and metric values during training\n",
        "history = model.fit(X, y, batch_size=16, epochs=30, #validation_data=(x_val, y_val), \n",
        "                    validation_split = 0.2, #automatically reserve part of the training data for validation\n",
        "                    verbose=1)\n",
        "\n",
        "# create the model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(X.shape[1],), name='hidden_layer1'))\n",
        "model.add(Dense(32, activation='relu', name='hidden_layer2'))\n",
        "model.add(Dense(1, kernel_initializer='normal', name='output_layer'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
        "\n",
        "# fit method train the model by slicing the data into batches of size batch_size and iterate over the entire dataset for given number of epochs\n",
        "# history holds a record of the loss values and metric values during training\n",
        "history = model.fit(X, y, batch_size=64, epochs=30, #validation_data=(x_val, y_val), \n",
        "                    validation_split = 0.2, #automatically reserve part of the training data for validation\n",
        "                    verbose=1)\n",
        "\n",
        "# create the model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(X.shape[1],), name='hidden_layer1'))\n",
        "model.add(Dense(32, activation='relu', name='hidden_layer2'))\n",
        "model.add(Dense(1, kernel_initializer='normal', name='output_layer'))\n",
        "\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
        "\n",
        "# fit method train the model by slicing the data into batches of size batch_size and iterate over the entire dataset for given number of epochs\n",
        "# history holds a record of the loss values and metric values during training\n",
        "history = model.fit(X, y, batch_size=128, epochs=30, #validation_data=(x_val, y_val), \n",
        "                    validation_split = 0.2, #automatically reserve part of the training data for validation\n",
        "                    verbose=1)\n",
        "\n",
        "# create the model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(X.shape[1],), name='hidden_layer1'))\n",
        "model.add(Dense(32, activation='relu', name='hidden_layer2'))\n",
        "model.add(Dense(1, kernel_initializer='normal', name='output_layer'))\n",
        "\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
        "\n",
        "# fit method train the model by slicing the data into batches of size batch_size and iterate over the entire dataset for given number of epochs\n",
        "# history holds a record of the loss values and metric values during training\n",
        "history = model.fit(X, y, batch_size=8, epochs=30, #validation_data=(x_val, y_val), \n",
        "                    validation_split = 0.2, #automatically reserve part of the training data for validation\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZxoAhzt8-HH"
      },
      "source": [
        "#Tune learning rates\n",
        "import keras.optimizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "y = df_le['JobSatisfaction']\n",
        "X = df_le.drop(['JobSatisfaction'],axis=1,inplace=False)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='elu', input_shape=(X.shape[1],), name='hidden_layer1'))\n",
        "model.add(Dense(32, activation='elu', name='hidden_layer2'))\n",
        "model.add(Dense(1, kernel_initializer='normal', name='output_layer'))\n",
        "\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer = Adam(lr = 0.001), metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
        "\n",
        "# fit method train the model by slicing the data into batches of size batch_size and iterate over the entire dataset for given number of epochs\n",
        "# history holds a record of the loss values and metric values during training\n",
        "history = model.fit(X, y, batch_size=8, epochs=100, #validation_data=(x_val, y_val), \n",
        "                    validation_split = 0.2, #automatically reserve part of the training data for validation\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41F_C3oq9Nya"
      },
      "source": [
        "#Different combinations if batch sizes, activation functions and neuron numbers\n",
        "import keras.optimizers\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "y = df_le['JobSatisfaction']\n",
        "X = df_le.drop(['JobSatisfaction'],axis=1,inplace=False)\n",
        "batch_sizes = [8,16,32,64,128]\n",
        "activations1 = ['elu','relu','linear']\n",
        "activations2 = ['elu','relu','linear']\n",
        "activations3 = ['elu','relu','linear']\n",
        "neurons = [[512,256,128],[256,64,32],[512,128,32],[128,32,16],[1024,128,32]]\n",
        "losses= [tf.keras.losses.MeanAbsoluteError(),'mse',]\n",
        "for ns in neurons:\n",
        "  for loss in losses:\n",
        "    for bs in batch_sizes:\n",
        "      for ac1 in activations1:\n",
        "        for ac2 in activations2:\n",
        "          for ac3 in activations3:\n",
        "            model = Sequential()\n",
        "            model.add(Dense(ns[0], activation=ac1, input_shape=(X.shape[1],), name='hidden_layer1'))\n",
        "            model.add(Dense(ns[1], activation=ac2, name='hidden_layer3'))\n",
        "            model.add(Dense(ns[2], activation=ac3, name='hidden_layer2'))\n",
        "            model.add(Dense(ns[3], kernel_initializer='normal', name='output_layer'))\n",
        "\n",
        "\n",
        "            model.compile(loss=loss, optimizer = Adam(lr = 0.01, decay=1e-03), metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
        "\n",
        "            # fit method train the model by slicing the data into batches of size batch_size and iterate over the entire dataset for given number of epochs\n",
        "            # history holds a record of the loss values and metric values during training\n",
        "            history = model.fit(X, y, batch_size=bs, epochs=30, #validation_data=(x_val, y_val), \n",
        "                                validation_split = 0.2, #automatically reserve part of the training data for validation\n",
        "                                verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfPOJbWB-CkE"
      },
      "source": [
        "**Neural Network with Selected Features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr9IDgVG-GZP"
      },
      "source": [
        "features = ['Age',\n",
        " 'CurrentJobTitleSelect',\n",
        " 'TitleFit',\n",
        " 'RemoteWork',\n",
        " 'WorkMLTeamSeatSelect',\n",
        " 'Country',\n",
        " 'CurrentEmployerType',\n",
        " 'WorkProductionFrequency',\n",
        " 'GenderSelect',\n",
        " 'FormalEducation']\n",
        "train = df_\n",
        "the_data = train[features+[\"JobSatisfaction\"]]\n",
        " \n",
        "\n",
        "the_data['Age'].fillna((the_data['Age'].mean()), inplace=True)\n",
        "the_data['CurrentJobTitleSelect'].fillna(the_data['CurrentJobTitleSelect'].mode()[0], inplace=True)\n",
        "the_data['TitleFit'].fillna(the_data['TitleFit'].mode()[0], inplace=True)\n",
        "the_data['GenderSelect'].fillna(the_data['GenderSelect'].mode()[0], inplace=True)\n",
        "the_data['Country'].fillna(the_data['Country'].mode()[0], inplace=True)\n",
        "the_data['WorkProductionFrequency'].fillna(the_data['WorkProductionFrequency'].mode()[0], inplace=True)\n",
        "the_data['RemoteWork'].fillna(the_data['RemoteWork'].mode()[0], inplace=True)\n",
        "the_data['WorkMLTeamSeatSelect'].fillna(the_data['WorkMLTeamSeatSelect'].mode()[0], inplace=True)\n",
        "the_data['CurrentEmployerType'].fillna(the_data['CurrentEmployerType'].mode()[0], inplace=True)\n",
        "the_data['FormalEducation'].fillna(the_data['FormalEducation'].mode()[0], inplace=True)\n",
        "train=the_data\n",
        "\n",
        "X = train.drop('JobSatisfaction', axis = 1)\n",
        "y = train['JobSatisfaction']\n",
        "\n",
        "categories = features\n",
        "one_hot = OneHotEncoder(handle_unknown='ignore')\n",
        "encoder = ColumnTransformer([('one_hot', one_hot, categories)],remainder = 'passthrough')\n",
        "X = encoder.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABnvAhoU-J1_"
      },
      "source": [
        "\n",
        "import keras.optimizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dropout\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation='elu', input_shape=(X.shape[1],), name='hidden_layer1'))\n",
        "model.add(Dropout(0.7, input_shape=(X.shape[1],)))\n",
        "model.add(Dense(128, activation='elu', name='hidden_layer3'))\n",
        "model.add(Dense(32, activation='tanh', name='hidden_layer2'))\n",
        "model.add(Dense(1, kernel_initializer='normal', name='output_layer'))\n",
        "\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer = Adam(lr = 0.001), metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', patience=10, \\\n",
        "                    verbose=1, mode='min',restore_best_weights=True) # Training will stop when minimum validation loss is achieved\n",
        "history = model.fit(X, y, batch_size=16, epochs=300, #validation_data=(x_val, y_val), \n",
        "                    validation_split = 0.2,  #automatically reserve part of the training data for validation\n",
        "                    callbacks = [es], verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C4Jb4fJ9mIN"
      },
      "source": [
        "Overall, even though the networks performance has been improved with fine-tuning of the hyperparameters, it could not reach the performance of previously implemented models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7na8e3LqJoOP"
      },
      "source": [
        "# Prediction with linear_model.Lasso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf9zk-SXMQk9"
      },
      "source": [
        "This was our first prediction to get used to Kaggle and submission. We have tried Lasso at first to have regularization to prevent overfitting due to high number of attributes after one hot encoding. We also optimized the alpha hyperparameter, and found it as 0.003 which is really small but gave a smaller RMSE in comparison to liner regression without L1 regularization. We have dropped the NaN's while training since we do not lose a lot of data and it were feasible, but filled the test data with mean for Age and mode for other categorical datasets. While in training we did not use cross validation to optimize parameters, but did use validation data by splitting. However, eventhough it gave around 1.83 RMSE in validation, it gave way worse in the submission in Kaggle. We are directly adding the code that was used in prediction here, where in later predictions we overcome these problems by using cross validation to better evaluate the models and also tried more models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQJ7Ef1jMIl_"
      },
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J7Fse-aPCG9"
      },
      "source": [
        "sheet = 'Sheet1'\n",
        "train = pd.read_excel(\"/content/train.xlsx\",sheet_name = sheet)\n",
        "features = ['Age',\n",
        " 'CurrentJobTitleSelect',\n",
        " 'TitleFit',\n",
        " 'RemoteWork',\n",
        " 'WorkMLTeamSeatSelect',\n",
        " 'Country',\n",
        " 'CurrentEmployerType',\n",
        " 'WorkProductionFrequency',\n",
        " 'GenderSelect',\n",
        " 'FormalEducation']\n",
        "\n",
        "predmodel = train[features+[\"JobSatisfaction\"]]\n",
        "predmodel = predmodel.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO-RJfgGPFPj"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import linear_model\n",
        "\n",
        "X = predmodel.drop('JobSatisfaction', axis = 1)\n",
        "y = predmodel['JobSatisfaction']\n",
        "\n",
        "categories = features.copy()\n",
        "if \"Age\" in categories:\n",
        "  categories.remove(\"Age\")\n",
        "\n",
        "one_hot = OneHotEncoder(handle_unknown='ignore')\n",
        "encoder = ColumnTransformer([('one_hot', one_hot, categories)],remainder = 'passthrough')\n",
        "X = encoder.fit_transform(X)\n",
        "\n",
        "model = linear_model.Lasso(alpha=0.003)\n",
        "model.fit(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJX8bg6vPwi9"
      },
      "source": [
        "test = pd.read_excel(\"/content/test.xlsx\",sheet_name = sheet)\n",
        "test_pred = test[features]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAggup8WPomW"
      },
      "source": [
        "cols = [\n",
        " 'CurrentJobTitleSelect',\n",
        " 'TitleFit',\n",
        " 'RemoteWork',\n",
        " 'WorkMLTeamSeatSelect',\n",
        " 'Country',\n",
        " 'CurrentEmployerType',\n",
        " 'WorkProductionFrequency',\n",
        " 'GenderSelect',\n",
        " 'FormalEducation']\n",
        "test_pred[cols]=test_pred[cols].fillna(test_pred.mode().iloc[0])\n",
        "test_pred['Age'].fillna((test_pred['Age'].mean()), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30p9akUQQBCB"
      },
      "source": [
        "son = encoder.transform(test_pred)\n",
        "predictions = model.predict(son)\n",
        "submission=pd.DataFrame(np.arange(1,1001), columns=['ID']) \n",
        "submission[\"Prediction\"] = predictions\n",
        "submission.to_csv(r'/content/firstpred.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T_marqsQPz-"
      },
      "source": [
        "# Prediction with Ridge Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmIjM206Qm98"
      },
      "source": [
        "We made our second submission with Ridge linear regression model which has L2 regularization. In here we have tried different models with the same dataset evaluated on cross validation RMSE, where Ridge Model gave the best score. Features were decided by the preprocessing step where we tried every possible combinations, alpha hyperparameter were choosen with trying the values from 1 to 50.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgjZJwv472ZK"
      },
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M80g43g_RLDI"
      },
      "source": [
        "import pandas as pd\n",
        "sheet = 'Sheet1'\n",
        "train = pd.read_excel(\"/content/train.xlsx\",sheet_name = sheet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azkv-nLcRMq1"
      },
      "source": [
        "features = ['Age',\n",
        " 'CurrentJobTitleSelect',\n",
        " 'TitleFit',\n",
        " 'RemoteWork',\n",
        " 'WorkMLTeamSeatSelect',\n",
        " 'Country',\n",
        " 'CurrentEmployerType',\n",
        " 'WorkProductionFrequency',\n",
        " 'GenderSelect',\n",
        " 'FormalEducation']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaqaLj8FRRHH"
      },
      "source": [
        "predmodel = train[features+[\"JobSatisfaction\"]]\n",
        "predmodel = predmodel.dropna()\n",
        "predmodel.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIYh_XlGRR0i"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "X = predmodel.drop('JobSatisfaction', axis = 1)\n",
        "y = predmodel['JobSatisfaction']\n",
        "\n",
        "categories = features.copy()\n",
        "one_hot = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "#Notice here we forgot to exclude Age from one hot encoding, which were solved in our next predictions\n",
        "\n",
        "encoder = ColumnTransformer([('one_hot', one_hot, categories)],remainder = 'passthrough')\n",
        "X = encoder.fit_transform(X)\n",
        "model = Ridge(alpha=41)\n",
        "\n",
        "#Here we tried bunch of different models with different hyperparameters\n",
        "#Used Linear Regression, KNN, LassoCV, Polynomial Regression with n=2, RidgeCV, Lassso\n",
        "#Best one were Ridge with optimized alpha parameter as 41, which gave mean of RMSE as around 1.975\n",
        "\n",
        "#model = LinearRegression(normalize=True)\n",
        "#model = KNeighborsClassifier(n_neighbors=40)\n",
        "#model = linear_model.LassoCV()\n",
        "#model = Pipeline([('poly', PolynomialFeatures(degree=2)),('linear', Ridge(alpha=42))])\n",
        "#model = linear_model.RidgeCV(scoring=\"neg_root_mean_squared_error\")\n",
        "#model = linear_model.Lasso(0.003)\n",
        "scores = cross_val_score(model, X, y, cv=10, scoring=\"neg_root_mean_squared_error\")\n",
        "score = scores.mean()\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89M03MReRRuS"
      },
      "source": [
        "model.fit(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNPs85WYSCpg"
      },
      "source": [
        "test = pd.read_excel(\"/content/test.xlsx\",sheet_name = sheet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spPk8dQJSDP5"
      },
      "source": [
        "test_pred = test[features]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgVjJ2OcSEsc"
      },
      "source": [
        "cols = [\n",
        " 'CurrentJobTitleSelect',\n",
        " 'TitleFit',\n",
        " 'RemoteWork',\n",
        " 'WorkMLTeamSeatSelect',\n",
        " 'Country',\n",
        " 'CurrentEmployerType',\n",
        " 'WorkProductionFrequency',\n",
        " 'GenderSelect',\n",
        " 'FormalEducation']\n",
        "test_pred[cols]=test_pred[cols].fillna(test_pred.mode().iloc[0])\n",
        "test_pred['Age'].fillna((test_pred['Age'].mean()), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYMSBUxzSIAi"
      },
      "source": [
        "son = encoder.transform(test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyI0mA31SUIk"
      },
      "source": [
        "predictions = model.predict(son)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IHzod7aSWgS"
      },
      "source": [
        "submission=pd.DataFrame(np.arange(1,1001), columns=['ID']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWYo2cq-SX3v"
      },
      "source": [
        "submission[\"Prediction\"] = predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6idSV7xbSZpc"
      },
      "source": [
        "submission.to_csv(r'/content/secondpred.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPe1q3A4Sc8a"
      },
      "source": [
        "# Prediction with Ridge Model - 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ8cKF0GSoux"
      },
      "source": [
        "In this approach, we fixed the encoding Age feature which was a mistake in the first prediction with Ridge model. Rest was the same, Kaggle score were higher as it was expected due to less number of features and meaningful Age feature with correct numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-iHqIG0Sogg"
      },
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "sheet = 'Sheet1'\n",
        "train = pd.read_excel(\"/content/train.xlsx\",sheet_name = sheet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cesY14eS9Mf"
      },
      "source": [
        "features = ['Age',\n",
        " 'CurrentJobTitleSelect',\n",
        " 'TitleFit',\n",
        " 'RemoteWork',\n",
        " 'WorkMLTeamSeatSelect',\n",
        " 'Country',\n",
        " 'CurrentEmployerType',\n",
        " 'WorkProductionFrequency',\n",
        " 'GenderSelect',\n",
        " 'FormalEducation']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGGyJV0_TAF3"
      },
      "source": [
        "predmodel = train[features+[\"JobSatisfaction\"]]\n",
        "predmodel = predmodel.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdNwc7eBTB-3"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "X = predmodel.drop('JobSatisfaction', axis = 1)\n",
        "y = predmodel['JobSatisfaction']\n",
        "\n",
        "categories = features.copy()\n",
        "## notice now we do not encode the Age\n",
        "if \"Age\" in categories:\n",
        "  categories.remove(\"Age\")\n",
        "one_hot = OneHotEncoder(handle_unknown='ignore')\n",
        "encoder = ColumnTransformer([('one_hot', one_hot, categories)],remainder = 'passthrough')\n",
        "X = encoder.fit_transform(X)\n",
        "model = Ridge(alpha=41)\n",
        "\n",
        "##Noticed that we also used different methods here, where the score of each one can be found in here and the most \n",
        "##optimized scores are already in the slides. We got the RMSE of selected model in here as 1.97681\n",
        "\n",
        "#model = LinearRegression(normalize=True) --> at best gave 1.9940331639523847 with this approach.\n",
        "#model = KNeighborsClassifier(n_neighbors=40)--> converges around 2.254 after n_neighbors>40\n",
        "#model = Pipeline([('poly', PolynomialFeatures(degree=2)),('linear', Ridge(alpha=42))]) --> Gave RMSE as 2.061884 and get worse in higher degrees\n",
        "#model = linear_model.Lasso(0.003) --> at best gave 1.982027523170488 with 0.003\n",
        "\n",
        "scores = cross_val_score(model, X, y, cv=10, scoring=\"neg_root_mean_squared_error\")\n",
        "score = scores.mean()\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8rz6wPYUFGA"
      },
      "source": [
        "model.fit(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB1gl4HGUHNW"
      },
      "source": [
        "test = pd.read_excel(\"/content/test.xlsx\",sheet_name = sheet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssVhACgwUJGK"
      },
      "source": [
        "test_pred = test[features]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC4HlunCUKxp"
      },
      "source": [
        "cols = [\n",
        " 'CurrentJobTitleSelect',\n",
        " 'TitleFit',\n",
        " 'RemoteWork',\n",
        " 'WorkMLTeamSeatSelect',\n",
        " 'Country',\n",
        " 'CurrentEmployerType',\n",
        " 'WorkProductionFrequency',\n",
        " 'GenderSelect',\n",
        " 'FormalEducation']\n",
        "test_pred[cols]=test_pred[cols].fillna(test_pred.mode().iloc[0])\n",
        "test_pred['Age'].fillna((test_pred['Age'].mean()), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51S9_ANaUNm6"
      },
      "source": [
        "son = encoder.transform(test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUP0MRuJUPwB"
      },
      "source": [
        "predictions = model.predict(son)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_iRiZt7USai"
      },
      "source": [
        "submission=pd.DataFrame(np.arange(1,1001), columns=['ID']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwnUM-6aUTvz"
      },
      "source": [
        "submission[\"Prediction\"] = predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w2hmEpZUVS7"
      },
      "source": [
        "submission.to_csv(r'/content/thirdpred.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c36s_Z7UZa_"
      },
      "source": [
        "# Prediction with Ridge Model - 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6IYAXCxUeau"
      },
      "source": [
        "In this approach, we mainly focused on alpha hyperparameter. In previous approaches, we tried different discrete alpha values between 1-50, but in here we also tried alpha values that are fractional at max 2 points after discrete values (e.g; X.xx) in order to better optimize our hyperparameter. Here we also tried to get scores with different models as it can be seen from below, however again the best result were given by Ridge Model which were than used in our prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EabEpoWaUdIM"
      },
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6W-M6cdVLvn"
      },
      "source": [
        "import pandas as pd\n",
        "sheet = 'Sheet1'\n",
        "train = pd.read_excel(\"/content/train.xlsx\",sheet_name = sheet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z21QgEihVNSs"
      },
      "source": [
        "features = ['Age',\n",
        " 'CurrentJobTitleSelect',\n",
        " 'TitleFit',\n",
        " 'RemoteWork',\n",
        " 'WorkMLTeamSeatSelect',\n",
        " 'Country',\n",
        " 'CurrentEmployerType',\n",
        " 'WorkProductionFrequency',\n",
        " 'GenderSelect',\n",
        " 'FormalEducation']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOmXSZauVPxl"
      },
      "source": [
        "predmodel = train[features+[\"JobSatisfaction\"]]\n",
        "predmodel = predmodel.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsVupH-tVRdJ"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "X = predmodel.drop('JobSatisfaction', axis = 1)\n",
        "y = predmodel['JobSatisfaction']\n",
        "\n",
        "categories = features.copy()\n",
        "if \"Age\" in categories:\n",
        "  categories.remove(\"Age\")\n",
        "one_hot = OneHotEncoder(handle_unknown='ignore')\n",
        "encoder = ColumnTransformer([('one_hot', one_hot, categories)],remainder = 'passthrough')\n",
        "X = encoder.fit_transform(X)\n",
        "\n",
        "#notice now we have our alpha as 39.22, that gave slightly better RMSE as 1.97679\n",
        "model = Ridge(alpha=39.22)\n",
        "\n",
        "##Scores were same as Prediction with Ridge - 2 for the methods below since there were no changes\n",
        "#model = LinearRegression(normalize=True)\n",
        "#model = KNeighborsClassifier(n_neighbors=70)\n",
        "#model = Pipeline([('poly', PolynomialFeatures(degree=2)),('linear', Ridge(alpha=39.22))])\n",
        "#model = linear_model.Lasso(0.003)\n",
        "\n",
        "scores = cross_val_score(model, X, y, cv=10, scoring=\"neg_root_mean_squared_error\")\n",
        "score = scores.mean()\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upJHHKK1Vshz"
      },
      "source": [
        "model.fit(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR9yWiJrVuOq"
      },
      "source": [
        "test = pd.read_excel(\"/content/test.xlsx\",sheet_name = sheet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccBSGoB0VwAd"
      },
      "source": [
        "test_pred = test[features]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YanKccCwVxjw"
      },
      "source": [
        "cols = [\n",
        " 'CurrentJobTitleSelect',\n",
        " 'TitleFit',\n",
        " 'RemoteWork',\n",
        " 'WorkMLTeamSeatSelect',\n",
        " 'Country',\n",
        " 'CurrentEmployerType',\n",
        " 'WorkProductionFrequency',\n",
        " 'GenderSelect',\n",
        " 'FormalEducation']\n",
        "test_pred[cols]=test_pred[cols].fillna(test_pred.mode().iloc[0])\n",
        "test_pred['Age'].fillna((test_pred['Age'].mean()), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv1Uuh6_Vznw"
      },
      "source": [
        "son = encoder.transform(test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcGY3uxYV1uF"
      },
      "source": [
        "predictions = model.predict(son)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6YIC1MQV2-5"
      },
      "source": [
        "submission=pd.DataFrame(np.arange(1,1001), columns=['ID']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saFG150bV405"
      },
      "source": [
        "submission[\"Prediction\"] = predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdQVVJFvV6NZ"
      },
      "source": [
        "submission.to_csv(r'/content/fifthpred.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}